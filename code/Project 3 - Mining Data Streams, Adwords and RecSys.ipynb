{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c461633a",
   "metadata": {},
   "source": [
    "### Enter full names of group members:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4648c5",
   "metadata": {},
   "source": [
    "##### Name A:\n",
    "##### Name B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "30d55dd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:07:58.095710200Z",
     "start_time": "2024-04-24T08:07:57.732715300Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy\n",
    "import numpy as np\n",
    "from sympy import prime\n",
    "from pathlib import Path  # for paths of files\n",
    "import csv\n",
    "import copy\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ANSI escape codes for colors\n",
    "class colors:\n",
    "    red = '\\033[91m'\n",
    "    green = '\\033[92m'\n",
    "    blue = '\\033[94m'\n",
    "    end = '\\033[0m'  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d4a780",
   "metadata": {},
   "source": [
    "### 1. DGIM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9287695e",
   "metadata": {},
   "source": [
    "#### 1.1. DGIM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2af55744",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:07:58.129064800Z",
     "start_time": "2024-04-24T08:07:58.010627600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Default DGIM parameters\n",
    "\n",
    "stream_path = 'data/my_stream.txt'\n",
    "\n",
    "# The window size\n",
    "N = 500 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3f339cf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:07:58.273586800Z",
     "start_time": "2024-04-24T08:07:58.166686Z"
    }
   },
   "outputs": [],
   "source": [
    "def dgim_algorithm(stream_path, N):\n",
    "    \n",
    "    # Create the buckets and initialize the timestamp\n",
    "    pos=1\n",
    "    bucket_list=[[]]\n",
    "\n",
    "\n",
    "    # Loop through the entire data stream, one bit at a time\n",
    "    with open(stream_path) as f:\n",
    "        while True:\n",
    "            bit = f.read(1)\n",
    "            \n",
    "            # Clause to break while loop at the end of the stream\n",
    "            if not bit:\n",
    "                break\n",
    "            \n",
    "            if bit==\"1\":\n",
    "                bucket_list[0].append(pos)\n",
    "                for b_index, bucket in enumerate(bucket_list):\n",
    "                    if len(bucket)==3:\n",
    "                        if len(bucket_list)>b_index+1:\n",
    "                            bucket_list[b_index+1].append(bucket[1])\n",
    "                            bucket_list[b_index]=[bucket[2]]\n",
    "                        else:\n",
    "                            bucket_list.append([bucket[1]])\n",
    "                            bucket_list[b_index]=[bucket[2]]\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "            # Failsafe\n",
    "            if len(bucket_list[0])>4:\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "            #We noticed alot of line-breaks in the my_stream.txt file. 103 of them. \n",
    "            #If you remove all of them the end time-stamp will become 1010000\n",
    "            #If you only remove the three trailing last ones the end time-stamp will become 1010099\n",
    "            #The answer only becomes truly correct if you remove all of them, so we filtered them out of the buckets like this.\n",
    "            if bit==\"1\" or bit ==\"0\":\n",
    "                pos+=1\n",
    "\n",
    "    end_time_stamp=pos-1\n",
    "            \n",
    "                            \n",
    "    return bucket_list, end_time_stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6dc1d2b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:02.958639400Z",
     "start_time": "2024-04-24T08:07:58.216925600Z"
    }
   },
   "outputs": [],
   "source": [
    "bucket = dgim_algorithm(stream_path, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6966be95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:03.024629200Z",
     "start_time": "2024-04-24T08:08:02.740645800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The updated list of timestamps buckets from DGIM algorithm: \n",
      " [[1010000], [1009992, 1009997], [1009984, 1009990], [1009964, 1009976], [1009945], [1009907], [1009722, 1009847], [1009335, 1009589], [1008598, 1009104], [1007062, 1008118], [1006021], [999737, 1003947], [987359, 995660], [979037], [962470], [862888, 929247], [663800, 796538], [265569, 530961]]\n",
      "The end timestamp: 1010000\n"
     ]
    }
   ],
   "source": [
    "print(f\"The updated list of timestamps buckets from DGIM algorithm: \\n {bucket[0]}\")\n",
    "print(f\"The end timestamp: {bucket[1]}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c273257",
   "metadata": {},
   "source": [
    "#### 1.2. Query the Bucket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4cb0343f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:03.026614900Z",
     "start_time": "2024-04-24T08:08:02.773162500Z"
    }
   },
   "outputs": [],
   "source": [
    "def actual_count(stream_path, k):\n",
    "    stream_list = []\n",
    "    with open(stream_path, 'r') as file:\n",
    "        for line in file:\n",
    "            stream_list.extend(list(map(int, line.strip())))\n",
    "\n",
    "    # Convert the list into a numpy array\n",
    "    stream_array = np.array(stream_list)\n",
    "    \n",
    "    return int(np.sum(stream_array[-k:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7f7f130f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:03.028619500Z",
     "start_time": "2024-04-24T08:08:02.820521700Z"
    }
   },
   "outputs": [],
   "source": [
    "def dgim_query(bucket, N, k): \n",
    "    # Extract the buckets and the end timestamp\n",
    "    bucket_list, end_time_stamp = bucket\n",
    "   \n",
    "    one_count=0\n",
    "    last_added=0\n",
    "    stamp=end_time_stamp\n",
    "    for bucket_index, bibuck in enumerate(bucket_list):\n",
    "        for stamp in reversed(bibuck):\n",
    "            if stamp<=end_time_stamp-k:\n",
    "                one_count-=last_added/2\n",
    "                break\n",
    "            else:\n",
    "                last_added=2**bucket_index\n",
    "                one_count+=last_added\n",
    "        if stamp<=end_time_stamp-k+1:\n",
    "            break\n",
    "    \n",
    "    return math.ceil(one_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "387e5be2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:03.051672500Z",
     "start_time": "2024-04-24T08:08:02.833637200Z"
    }
   },
   "outputs": [],
   "source": [
    "# List of queries\n",
    "K = [10, 50, 100, 300, 500] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7702bc6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:07.873886500Z",
     "start_time": "2024-04-24T08:08:02.864005700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------\n",
      "The total 1s in the last 10 bits by DGIM: 4\n",
      "The true count of 1s in the last 10 bits: 5\n",
      "The DGIM error for predicted 1s in the last 10 bits:     20.0 %\n",
      "---------------------------------------------------------------\n",
      "The total 1s in the last 50 bits by DGIM: 25\n",
      "The true count of 1s in the last 50 bits: 26\n",
      "The DGIM error for predicted 1s in the last 50 bits:     3.85 %\n",
      "---------------------------------------------------------------\n",
      "The total 1s in the last 100 bits by DGIM: 61\n",
      "The true count of 1s in the last 100 bits: 51\n",
      "The DGIM error for predicted 1s in the last 100 bits:     19.61 %\n",
      "---------------------------------------------------------------\n",
      "The total 1s in the last 300 bits by DGIM: 173\n",
      "The true count of 1s in the last 300 bits: 150\n",
      "The DGIM error for predicted 1s in the last 300 bits:     15.33 %\n",
      "---------------------------------------------------------------\n",
      "The total 1s in the last 500 bits by DGIM: 269\n",
      "The true count of 1s in the last 500 bits: 241\n",
      "The DGIM error for predicted 1s in the last 500 bits:     11.62 %\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------------------------------------\")\n",
    "for k in K:\n",
    "    dgim_count = dgim_query(bucket, 500, k)\n",
    "    true_count = actual_count(stream_path, k)\n",
    "    \n",
    "    print(f\"The total 1s in the last {k} bits by DGIM: {dgim_count}\")\n",
    "    print(f\"The true count of 1s in the last {k} bits: {true_count}\")\n",
    "    print(f\"The DGIM error for predicted 1s in the last {k} bits: \\\n",
    "    {round(abs(100*(dgim_count-true_count))/true_count,2)} %\")\n",
    "    print(\"---------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaaceac",
   "metadata": {},
   "source": [
    "### 2. Bloom filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "92883c93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:07.948732700Z",
     "start_time": "2024-04-24T08:08:07.876650Z"
    }
   },
   "outputs": [],
   "source": [
    "# Username data for the creation of bloom filters - B\n",
    "data_file = (Path(\"data/bloom_username\").with_suffix('.csv'))\n",
    "\n",
    "# Test data to check the functionality and false positive rate\n",
    "test1_file = (Path(\"data/test1_username\").with_suffix('.csv'))\n",
    "test2_file = (Path(\"data/test2_username\").with_suffix('.csv'))\n",
    "\n",
    "# Default bloom filter parameters\n",
    "bloom_size = 1500000 # parameter N\n",
    "h = 3 # number of hash functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6c5e5c13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:07.998979100Z",
     "start_time": "2024-04-24T08:08:07.952250400Z"
    }
   },
   "outputs": [],
   "source": [
    "# create an array of bloom filter with zeros\n",
    "B = np.zeros(bloom_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1c033746",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:08.096958300Z",
     "start_time": "2024-04-24T08:08:07.986966800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 0., 0., ..., 0., 0., 0.])"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d73d660",
   "metadata": {},
   "source": [
    "#### 2.1. Create Bloom filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "75b69edf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:08.198911700Z",
     "start_time": "2024-04-24T08:08:08.102464800Z"
    }
   },
   "outputs": [],
   "source": [
    "def generatePrimes(n):\n",
    "    i = 3\n",
    "    primes=[2]\n",
    "    flag = False\n",
    "    while(len(primes) < n):\n",
    "        flag = True\n",
    "        for j in primes:\n",
    "            if math.floor(math.sqrt(i)) + 1 <= j:\n",
    "                break\n",
    "            elif (i%j == 0):\n",
    "                flag = False\n",
    "                break\n",
    "        if(flag):\n",
    "            primes.append(i)\n",
    "        i+=1\n",
    "    \n",
    "    return primes\n",
    "\n",
    "def hash_function(p,N):\n",
    "    return lambda s: (sum([ord(s[i])*(p**(i+1)) for i in range(len(s))])%N)\n",
    "\n",
    "def generate_hash(h, N):\n",
    "    hash_list = []\n",
    "\n",
    "    prime_list_length=math.floor(math.sqrt(N))\n",
    "    #Generate h different random primes to make hash functions more random\n",
    "    seeds=random.sample(range(0, prime_list_length), h)\n",
    "    primes=generatePrimes(prime_list_length)\n",
    "    primes=[primes[seeds[i]] for i in range(h)]\n",
    "    \n",
    "\n",
    "    for p in range(h):\n",
    "        func = hash_function(primes[p],N)\n",
    "        hash_list.append(func)\n",
    "    return hash_list\n",
    "\n",
    "def hash_function(p,N):\n",
    "    return lambda s: (sum([ord(s[i])*(p**(i+1)) for i in range(len(s))])%N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a75aeecb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:08.280090400Z",
     "start_time": "2024-04-24T08:08:08.202180600Z"
    }
   },
   "outputs": [],
   "source": [
    "hashes = generate_hash(h, bloom_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0d2d4c25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:08.330717900Z",
     "start_time": "2024-04-24T08:08:08.284448Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_bloom_filter(B, hashes, data):\n",
    "    with data.open(encoding=\"utf-8\") as f:\n",
    "        for name in f:\n",
    "            for hash in hashes:\n",
    "                index=hash(name.strip())\n",
    "                B[index]=1\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fe79b434",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:14.314934800Z",
     "start_time": "2024-04-24T08:08:08.332892100Z"
    }
   },
   "outputs": [],
   "source": [
    "bloom_array = create_bloom_filter(B, hashes, data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d7ce957d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:14.393825300Z",
     "start_time": "2024-04-24T08:08:14.336361700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 1., 1., ..., 1., 0., 0.])"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bloom_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff48616",
   "metadata": {},
   "source": [
    "#### 2.2. Verify usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "530485d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:14.445422400Z",
     "start_time": "2024-04-24T08:08:14.381800800Z"
    }
   },
   "outputs": [],
   "source": [
    "def single_verify_username(bloom_array, hashes, new_user):\n",
    "    code=0\n",
    "    existing_entries=1\n",
    "    for hash in hashes:\n",
    "        if bloom_array[hash(new_user.strip())]==0:\n",
    "            existing_entries=0\n",
    "            break\n",
    "    return existing_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b6edf315",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:14.501575300Z",
     "start_time": "2024-04-24T08:08:14.446435800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feel free to test different usernames here\n",
    "\n",
    "new_username = \"hubble2010\"\n",
    "\n",
    "#new_username = \"ShambaTDT4305\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "22690d64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:14.573281200Z",
     "start_time": "2024-04-24T08:08:14.511767800Z"
    }
   },
   "outputs": [],
   "source": [
    "user_code = single_verify_username(bloom_array, hashes, new_username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b7730361",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:14.633481500Z",
     "start_time": "2024-04-24T08:08:14.580702100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[91mUsername hubble2010 has been taken. Try again!\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "if user_code == 1:\n",
    "    print(colors.red + f\"Username {new_username} has been taken. Try again!\" + colors.end)\n",
    "elif user_code == 0:\n",
    "    print(colors.green + f\"Username {new_username} is available. Congrats!\" + colors.end)\n",
    "else:\n",
    "    print(colors.blue + f\"Wrong pass code. Please reverify!\" + colors.end)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "080d7f88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:14.713051300Z",
     "start_time": "2024-04-24T08:08:14.640914700Z"
    }
   },
   "outputs": [],
   "source": [
    "def group_verify_username(bloom_array, hashes, data):\n",
    "    # Initialize counts\n",
    "    total_name = 0\n",
    "    taken_name = 0\n",
    "    \n",
    "    with data.open(encoding=\"utf-8\") as f:\n",
    "        for name in f:\n",
    "            total_name+=1\n",
    "            taken_name+=single_verify_username(bloom_array, hashes, name)\n",
    "            \n",
    "    return round(taken_name/total_name*100,2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4725c4b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:19.031939700Z",
     "start_time": "2024-04-24T08:08:14.715395700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "Percentage of username seen before from test 1: 100.0%\n",
      "----------------------------------------------------------\n",
      "Percentage of username seen before from test 2: 23.78%\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------------------------------------\")\n",
    "user_total = group_verify_username(bloom_array, hashes, test1_file)\n",
    "print(f\"Percentage of username seen before from test 1: {user_total}%\")\n",
    "print(\"----------------------------------------------------------\")\n",
    "user_total = group_verify_username(bloom_array, hashes, test2_file)\n",
    "print(f\"Percentage of username seen before from test 2: {user_total}%\")\n",
    "print(\"----------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9488c00b",
   "metadata": {},
   "source": [
    "### 3. Flajolet-Martin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dae74f8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:19.099434700Z",
     "start_time": "2024-04-24T08:08:19.036063100Z"
    }
   },
   "outputs": [],
   "source": [
    "def r(a):\n",
    "    for i in range(a.bit_length()):\n",
    "        if a & (1 << i):\n",
    "            return i   \n",
    "    return 0\n",
    "\n",
    "def flajolet_martin(input_stream):\n",
    "    R = 0  # Initialize maximum rightmost zero bit position to 0\n",
    "    h=lambda x: (6*x+1)%5\n",
    "    # To-do! Define hash function h(x) = 6x + 1 mod 5\n",
    "    \n",
    "    for element in input_stream:\n",
    "        temp_r=r(h(element))\n",
    "        R=max(temp_r,R)\n",
    "    # To-do! Iterate over the input stream and update maximum rightmost zero bit position\n",
    "    \n",
    "\n",
    "    # Estimate the number of distinct elements\n",
    "    distinct_estimate = 2 ** R\n",
    "\n",
    "    return distinct_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c7a283b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:19.167610800Z",
     "start_time": "2024-04-24T08:08:19.100570900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "Distinct elements (estimated) in input stream 1: 2\n",
      "-----------------------------------------------------\n",
      "Distinct elements (estimated) in input stream 2: 4\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Input stream\n",
    "input_stream1 = [1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1]\n",
    "input_stream2 = [1, 3, 2, 1, 2, 3, 4, 3, 1, 2, 3, 1]\n",
    "\n",
    "# Run the Flajolet-Martin algorithm\n",
    "distinct_estimate1 = flajolet_martin(input_stream1)\n",
    "distinct_estimate2 = flajolet_martin(input_stream2)\n",
    "\n",
    "# Print the estimated number of distinct elements\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(f\"Distinct elements (estimated) in input stream 1:\", distinct_estimate1)\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(f\"Distinct elements (estimated) in input stream 2:\", distinct_estimate2)\n",
    "print(\"-----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3051ee5",
   "metadata": {},
   "source": [
    "### 4. Adword "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805b08ba",
   "metadata": {},
   "source": [
    "#### 4.1. Greedy Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a58d6ca8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:19.259486900Z",
     "start_time": "2024-04-24T08:08:19.170239800Z"
    }
   },
   "outputs": [],
   "source": [
    "# User queries\n",
    "queries = [\"big data\", \"big data\", \"big data\",\"bloom filters\", \"bloom filters\", \"bloom filters\",\n",
    "           \"flajolet martin\", \"flajolet martin\", \"flajolet martin\", \"dgim algorithm\", \"dgim algorithm\", \"dgim algorithm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "66ee11dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:19.307790Z",
     "start_time": "2024-04-24T08:08:19.233820800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Company A B C and D keywords and budget $$$\n",
    "global_companies = {\n",
    "        'A': [\"big data\", \"bloom filters\", 3],\n",
    "        'B': [\"flajolet martin\", 3],\n",
    "        'C': [\"flajolet martin\", \"dgim algorithm\", 3],\n",
    "        'D': [\"big data\", 3],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fd6eb986",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:19.352837200Z",
     "start_time": "2024-04-24T08:08:19.287776100Z"
    }
   },
   "outputs": [],
   "source": [
    "def greedy_algorithm(local_companies, queries):\n",
    "    # Initial revenue\n",
    "    revenue = 0\n",
    "    for q in queries:\n",
    "        order = random.sample(list(local_companies.keys()), len(local_companies))\n",
    "        match=False\n",
    "        for company in order:\n",
    "            bids = local_companies[company]\n",
    "            for i in range(0, len(bids)-1):\n",
    "                if bids[i] == q:\n",
    "                    if bids[-1] > 0:\n",
    "                        match=True\n",
    "                        bids[-1] -= 1\n",
    "                        revenue += 1\n",
    "                        break\n",
    "            if match:\n",
    "                break\n",
    "\n",
    "    \n",
    "    return revenue\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7c9378f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:19.437316400Z",
     "start_time": "2024-04-24T08:08:19.361217300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trials using Greedy Algorithm...\n",
      "------------------------------------------------\n",
      "Trial 1 - Revenue generated: 8\n",
      "Trial 2 - Revenue generated: 9\n",
      "Trial 3 - Revenue generated: 9\n",
      "Trial 4 - Revenue generated: 8\n",
      "Trial 5 - Revenue generated: 9\n",
      "Trial 6 - Revenue generated: 8\n",
      "Trial 7 - Revenue generated: 7\n",
      "Trial 8 - Revenue generated: 8\n",
      "Trial 9 - Revenue generated: 7\n",
      "Trial 10 - Revenue generated: 10\n",
      "------------------------------------------------\n",
      "Average revenue generated for all trials:  8.3\n"
     ]
    }
   ],
   "source": [
    "total_revenue = 0\n",
    "total_trials = 10\n",
    "print(\"Starting trials using Greedy Algorithm...\")\n",
    "print(\"------------------------------------------------\")\n",
    "for i in range(total_trials):\n",
    "    local_companies = copy.deepcopy(global_companies)\n",
    "    revenue = greedy_algorithm(local_companies, queries)\n",
    "    total_revenue = total_revenue + revenue\n",
    "    print(f\"Trial {i+1} - Revenue generated: {revenue}\")\n",
    "print(\"------------------------------------------------\")   \n",
    "print(\"Average revenue generated for all trials: \",total_revenue/total_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49fda97",
   "metadata": {},
   "source": [
    "#### 4.2. Balance Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9af1b93d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:19.516198800Z",
     "start_time": "2024-04-24T08:08:19.443841200Z"
    }
   },
   "outputs": [],
   "source": [
    "def balance_algorithm(local_companies, queries):\n",
    "    # Initial revenue\n",
    "    revenue = 0\n",
    "    for q in queries:\n",
    "        candidate_companies=[]\n",
    "        buy_in=0\n",
    "        for company, bids in local_companies.items():\n",
    "            if q in bids and bids[-1]>0:\n",
    "                if bids[-1]>buy_in:\n",
    "                    buy_in=bids[-1]\n",
    "                    candidate_companies=[company]\n",
    "                elif bids[-1]==buy_in:\n",
    "                    candidate_companies.append(company)\n",
    "        if candidate_companies:\n",
    "            local_companies[candidate_companies[random.randint(0,len(candidate_companies)-1)]][-1]-=1\n",
    "            revenue+=1\n",
    "\n",
    "\n",
    "    \n",
    "    return revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8b975413",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:19.569016600Z",
     "start_time": "2024-04-24T08:08:19.515107600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trials using Balance Algorithm...\n",
      "-------------------------------------------\n",
      "Trial 1 - Revenue generated: 10\n",
      "Trial 2 - Revenue generated: 9\n",
      "Trial 3 - Revenue generated: 9\n",
      "Trial 4 - Revenue generated: 9\n",
      "Trial 5 - Revenue generated: 9\n",
      "Trial 6 - Revenue generated: 8\n",
      "Trial 7 - Revenue generated: 9\n",
      "Trial 8 - Revenue generated: 9\n",
      "Trial 9 - Revenue generated: 9\n",
      "Trial 10 - Revenue generated: 9\n",
      "-------------------------------------------\n",
      "Average revenue generated for all trials:  9.0\n"
     ]
    }
   ],
   "source": [
    "total_revenue = 0\n",
    "total_trials = 10\n",
    "print(\"Starting trials using Balance Algorithm...\")\n",
    "print(\"-------------------------------------------\")\n",
    "for i in range(total_trials):\n",
    "    local_companies = copy.deepcopy(global_companies)\n",
    "    revenue = balance_algorithm(local_companies, queries)\n",
    "    total_revenue = total_revenue + revenue\n",
    "    print(f\"Trial {i+1} - Revenue generated: {revenue}\")\n",
    "print(\"-------------------------------------------\")   \n",
    "print(\"Average revenue generated for all trials: \",total_revenue/total_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a2ef9e",
   "metadata": {},
   "source": [
    "### 5. Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "86174f88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:19.664745300Z",
     "start_time": "2024-04-24T08:08:19.567471300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ratings matrix (each row corresponds to a movie, and each column corresponds to a user)\n",
    "ratings_matrix = np.array([\n",
    "    [1, 0, 3, 0, 0, 5, 0, 0, 5, 0, 4, 0],\n",
    "    [0, 0, 5, 4, 0, 0, 4, 0, 0, 2, 1, 3],\n",
    "    [2, 4, 0, 1, 2, 0, 3, 0, 4, 3, 5, 0],\n",
    "    [0, 2, 4, 0, 5, 0, 0, 4, 0, 0, 2, 0],\n",
    "    [0, 0, 4, 3, 4, 2, 0, 0, 0, 0, 2, 5],\n",
    "    [1, 0, 3, 0, 3, 0, 0, 2, 0, 0, 4, 0]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90516ed2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c92e8e0",
   "metadata": {},
   "source": [
    "#### 5.1. User-User Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0749438f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:19.745304600Z",
     "start_time": "2024-04-24T08:08:19.670034200Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_similar_vectors(rating_matrix,target_index,neigh):\n",
    "    similarity_scores=[]\n",
    "    user_vector = rating_matrix[target_index]\n",
    "    for i in range(len(rating_matrix)):\n",
    "        if i==target_index:\n",
    "            continue\n",
    "        similarity=cosine_similarity([user_vector],[rating_matrix[i]])[0][0]\n",
    "        similarity_scores.append([i,similarity])\n",
    "    x=lambda sim: sim[1]\n",
    "    similarity_scores.sort(key=x)\n",
    "    return similarity_scores[-neigh:]\n",
    "\n",
    "def user_cf(rate_m, tup_mu, neigh):\n",
    "    tup_mu=[tup_mu[0]-1,tup_mu[1]-1]\n",
    "    # To-do! implement a user-user CF using cosine similarity as distance measure\n",
    "    similar_users=find_similar_vectors(np.transpose(rate_m),tup_mu[1],neigh)\n",
    "\n",
    "    prediction=sum([rate_m[tup_mu[0]][user[0]]*user[1] for user in similar_users]) / sum([user[1] for user in similar_users])\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c153de09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:08:19.831894500Z",
     "start_time": "2024-04-24T08:08:19.746381800Z"
    }
   },
   "outputs": [],
   "source": [
    "# List of tuple of movie rating by users to be predicted e.g (1, 5) refers to the rating of movie 1 by user 5\n",
    "list_mu_query = [(1, 5), (3, 3)]\n",
    "\n",
    "# Neighbor selection (|N|)\n",
    "neigh = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "22f8e8d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:09:14.451515Z",
     "start_time": "2024-04-24T08:09:14.267949600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "The predicted rating of movie 1 by user 5: 1.4158544560666992 (User-User CF)\n",
      "-----------------------------------------------------------------\n",
      "The predicted rating of movie 3 by user 3: 1.4938710151784431 (User-User CF)\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------------------------------------------------\")   \n",
    "for mu_query in list_mu_query:\n",
    "    predicted_rating = user_cf(ratings_matrix, mu_query, neigh)\n",
    "    print(f\"The predicted rating of movie {mu_query[0]} by user {mu_query[1]}: {predicted_rating} (User-User CF)\")\n",
    "    print(\"-----------------------------------------------------------------\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4774134",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7217e4ed",
   "metadata": {},
   "source": [
    "#### 5.2. Item-Item Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c03be5d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:25:43.703317900Z",
     "start_time": "2024-04-24T08:25:43.572204700Z"
    }
   },
   "outputs": [],
   "source": [
    "def item_cf(rate_m, tup_mu, neigh):\n",
    "    rate_m_2 = rate_m.copy().astype(np.float32)\n",
    "    print(rate_m_2)\n",
    "    # To-do! implement a item-item CF using cosine similarity as distance measure\n",
    "    tup_mu=[tup_mu[0]-1,tup_mu[1]-1]\n",
    "    for row, movie in enumerate(rate_m_2):\n",
    "        average = np.average(movie)\n",
    "        non_zero_avg = average * (len(movie)/np.count_nonzero(movie))\n",
    "        for col, user in enumerate(movie):\n",
    "            if rate_m[row][col]:\n",
    "                rate_m_2[row][col] = user-non_zero_avg\n",
    "    \n",
    "    # To-do! implement a item-item CF using cosine similarity as distance measure\n",
    "    similar_movies = find_similar_vectors(rate_m_2, tup_mu[0], neigh)\n",
    "    prediction=sum([rate_m[movie[0]][tup_mu[1]]*movie[1] for movie in similar_movies]) / sum([movie[1] for movie in similar_movies])\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c4b5ffe6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:25:46.077939500Z",
     "start_time": "2024-04-24T08:25:45.976747300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "[[1. 0. 3. 0. 0. 5. 0. 0. 5. 0. 4. 0.]\n",
      " [0. 0. 5. 4. 0. 0. 4. 0. 0. 2. 1. 3.]\n",
      " [2. 4. 0. 1. 2. 0. 3. 0. 4. 3. 5. 0.]\n",
      " [0. 2. 4. 0. 5. 0. 0. 4. 0. 0. 2. 0.]\n",
      " [0. 0. 4. 3. 4. 2. 0. 0. 0. 0. 2. 5.]\n",
      " [1. 0. 3. 0. 3. 0. 0. 2. 0. 0. 4. 0.]]\n",
      "The predicted rating of movie 1 by user 5: 2.586406888682535 (Item-Item CF)\n",
      "-----------------------------------------------------------------\n",
      "[[1. 0. 3. 0. 0. 5. 0. 0. 5. 0. 4. 0.]\n",
      " [0. 0. 5. 4. 0. 0. 4. 0. 0. 2. 1. 3.]\n",
      " [2. 4. 0. 1. 2. 0. 3. 0. 4. 3. 5. 0.]\n",
      " [0. 2. 4. 0. 5. 0. 0. 4. 0. 0. 2. 0.]\n",
      " [0. 0. 4. 3. 4. 2. 0. 0. 0. 0. 2. 5.]\n",
      " [1. 0. 3. 0. 3. 0. 0. 2. 0. 0. 4. 0.]]\n",
      "The predicted rating of movie 3 by user 3: 3.0 (Item-Item CF)\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------------------------------------------------\")   \n",
    "for mu_query in list_mu_query:\n",
    "    predicted_rating = item_cf(ratings_matrix, mu_query, neigh)\n",
    "    print(f\"The predicted rating of movie {mu_query[0]} by user {mu_query[1]}: {predicted_rating} (Item-Item CF)\")\n",
    "    print(\"-----------------------------------------------------------------\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0892ce96",
   "metadata": {},
   "source": [
    "### Provide concise answers to all 5 cases in the Project 3 description below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc34aad",
   "metadata": {},
   "source": [
    "#### Case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a669b54b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:09:15.110694Z",
     "start_time": "2024-04-24T08:09:14.894185400Z"
    }
   },
   "outputs": [],
   "source": [
    "# While the number of buckets is log(N) over N bits, the timestamp we have to save for each bucket will also need a space complexity of Log(N). Each timestamp increases in size logarithmically as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b85a6",
   "metadata": {},
   "source": [
    "#### Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e8340d9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T09:03:45.829047400Z",
     "start_time": "2024-04-24T09:03:45.751197800Z"
    }
   },
   "outputs": [],
   "source": [
    "# It is possible that the name is flagged as taken even though it is available. The Bloom Filter algorithm uses hash functions that checks if a name is already taken, and there will always be a chance that two different usernames hashes into the same output. With multiple hash functions, the chance decreases, but it will still be possible. In this case the Bloom Filter will flag a free username as taken. It would be possible for a site-admin to manually use any search function on the given username in the database to see if its actually taken. \n",
    "\n",
    "# In the opposite case, where a friend has claimed that a username flagged as available is already taken, there should be no possible way for this to happen in the Bloom Filter algorithm. This is because the hash function for a username will always give the same output no matter what, and when that username is then flagged as taken, there is no way for the username to have the flag of available. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f16cad2",
   "metadata": {},
   "source": [
    "#### Case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "97d9b9fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:09:15.280173100Z",
     "start_time": "2024-04-24T08:09:15.211769200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Enter answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb9e628",
   "metadata": {},
   "source": [
    "#### Case 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0a78ac31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:09:15.422610500Z",
     "start_time": "2024-04-24T08:09:15.287516100Z"
    }
   },
   "outputs": [],
   "source": [
    "# The greedy algorithm with the given input will have:\n",
    "# Worst possible outcome: 6\n",
    "# Best possible outcome: 12\n",
    "# Competitive ratio: 1/2\n",
    "\n",
    "# The balance algorithm with the given input will have:\n",
    "# Worst possible outcome: 8\n",
    "# Best possible outcome: 12\n",
    "# Competitive ratio: The general competitive ratio for the balance algorithm is 1-1/e=0.63. In our case the competitive ratio is 8/12=0.66, because we have so few companies in our example. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c341065",
   "metadata": {},
   "source": [
    "#### Case 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2e3aa9df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T08:09:17.281485700Z",
     "start_time": "2024-04-24T08:09:15.887818Z"
    }
   },
   "outputs": [],
   "source": [
    "# Enter answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
